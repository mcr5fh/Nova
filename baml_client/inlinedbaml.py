###############################################################################
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
###############################################################################

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code.
#
# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long
# fmt: off

file_map = {
    
    "agent.baml": "// Enum for message roles\nenum MessageRole {\n  User\n  Assistant\n  Tool\n}\n\n// Message structure for conversation history\nclass Message {\n  role MessageRole\n  content string\n  tool_call_id string?\n  tool_name string?\n}\n\n// Tool definitions\nenum ToolName {\n  FileRead\n  FileWrite\n  GitStatus\n  RunTests\n}\n\n// Tool call structure\nclass ToolCall {\n  tool ToolName\n  args string  // JSON string of arguments\n}\n\n// Enum for agent response type\nenum AgentResponseType {\n  ToolCall\n  Reply\n}\n\n// Agent can either call a tool or reply to user\nclass AgentResponse {\n  type AgentResponseType\n  tool_call ToolCall?\n  message string?\n}\n\n// Main agent loop function\nfunction AgentLoop(\n  messages: Message[],\n  working_dir: string\n) -> AgentResponse {\n  client GPT4o\n\n  prompt #\"\n    You are an AI coding agent helping developers accomplish tasks.\n\n    Working directory: {{ working_dir }}\n\n    You have access to these tools:\n    - FileRead(path: str) -> str: Read file contents\n    - FileWrite(path: str, content: str) -> str: Write file contents\n    - GitStatus() -> str: Check git status\n    - RunTests(path: str) -> str: Run pytest on path\n\n    Execute ONE tool at a time (no parallel execution).\n    After using a tool, wait for the result before deciding next action.\n    When task is complete, respond with type=\"reply\".\n\n    Conversation history:\n    {% for msg in messages %}\n    {{ msg.role }}: {{ msg.content }}\n    {% endfor %}\n\n    What do you want to do next?\n\n    Respond in this format:\n    {\n      \"type\": \"tool_call\" | \"reply\",\n      \"tool_call\": {\n        \"tool\": \"ToolName\",\n        \"args\": \"{\\\"arg1\\\": \\\"value1\\\"}\"\n      },\n      \"message\": \"Your response to user\"\n    }\n  \"#\n}\n",
    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\n// OpenAI client for agent loop\nclient<llm> GPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n",
    "generators.baml": "// This helps auto-generate libraries you can use in the language of your choice.\ngenerator target {\n    // Python/Pydantic for this project\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n}\n",
}

def get_baml_files():
    return file_map